{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "import time\n",
    "import datetime\n",
    "import itertools\n",
    "\n",
    "from reacher_def import RotReacherEnv\n",
    "import utils\n",
    "import ce_planner\n",
    "\n",
    "params = {'axes.labelsize': 12,   \n",
    "          'font.size': 12,   \n",
    "          'legend.fontsize': 10,   \n",
    "          'xtick.labelsize': 12,\n",
    "          'ytick.labelsize': 12,   \n",
    "          'text.usetex': False,   \n",
    "          'figure.figsize': [4, 4]}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_experiments(suffix, mode, lstm_units, models_dir='log', unit='m',\n",
    "                           save_dir=None, render_on=False, plot_on=False, **kwargs):\n",
    "    ''' Here we perform the test experiments in the 60 degree rotation environment for the trained models.\n",
    "    Every experiment has a certain amount of episodes of which each has 28 steps, i.e. 2s, max.\n",
    "    We store the outcome in a DataFrame so that we can easily access the results.'''\n",
    "    assert unit in ['m', 'cm']\n",
    "    \n",
    "    if save_dir is None:\n",
    "        save_dir = os.path.join('analysis', 'ex_models_{}'.format(datetime.datetime.now().strftime(\"%d_%H_%M_%S\")))\n",
    "    else:\n",
    "        save_dir = os.path.join('analysis', save_dir)\n",
    "    utils.make_dir(save_dir)\n",
    "    save_dir = os.path.join(save_dir, str(suffix)+'.pkl')\n",
    "    \n",
    "    env_path = os.path.join(Path().resolve(), 'rot_reacher_humanlike.xml')\n",
    "    \n",
    "    models_dir = os.path.join(Path().resolve(), models_dir)\n",
    "    dir_names = os.listdir(models_dir)\n",
    "    dir_names_pure = list(map(lambda name: name.split('_')[-2]+'_'+name.split('_')[-1], dir_names))\n",
    "    if not mode+'_'+str(lstm_units) in dir_names_pure:\n",
    "        raise FileNotFoundError('Data not in directory')\n",
    "    else:\n",
    "        match_idx = dir_names_pure.index(mode+'_'+str(lstm_units))\n",
    "        log_path = os.path.join('log', dir_names[match_idx])\n",
    "        model_dir = os.path.join(models_dir, dir_names[match_idx])\n",
    "    \n",
    "    unit_scaling = 100. if unit == 'm' else 1.\n",
    "\n",
    "    model, settings, _ = utils.load_latest_model(model_dir=model_dir)\n",
    "\n",
    "    data_to_store = pd.DataFrame()\n",
    "    \n",
    "    is_rendering = False\n",
    "    \n",
    "    ### loop through all parameters and perform the experiments\n",
    "    for exp in range(kwargs['n_experiments']):\n",
    "        ex_time = time.time()\n",
    "        print('Running experiment {}...'.format(exp+1))\n",
    "        ### initialize the environment (mode is not important since we're in test mode anyway)\n",
    "        env = RotReacherEnv(mode=settings['mode'], \n",
    "                            model_path=env_path, \n",
    "                            max_action=kwargs[\"max_action\"], \n",
    "                            test_mode=True)\n",
    "\n",
    "        observations = np.ones([kwargs['n_trials']*(kwargs['n_env_step_max']+1),2])*np.nan\n",
    "        velocities = np.ones([kwargs['n_trials']*(kwargs['n_env_step_max']+1),2])*np.nan\n",
    "        actions = np.ones([kwargs['n_trials']*(kwargs['n_env_step_max']+1),2])*np.nan\n",
    "        reset_bits = np.ones([kwargs['n_trials']*(kwargs['n_env_step_max']+1),1])*np.nan\n",
    "\n",
    "        global_step_counter = 0\n",
    "\n",
    "        ### now loop through the trials in one experiment\n",
    "        for trial in range(kwargs['n_trials']):\n",
    "            obs = env.reset_model()[:2]\n",
    "            vels = env.sim.get_state().qvel[:2]\n",
    "            observations[global_step_counter] = obs\n",
    "            velocities[global_step_counter] = vels\n",
    "            \n",
    "            new_plan = None\n",
    "            local_step_counter = 0\n",
    "            at_goal_counter = 0\n",
    "            goal = env.goal\n",
    "                            \n",
    "            ### these are the variables we want to store (we rotate our observations such that \n",
    "            ### they are all normalized)\n",
    "            angular_error = np.nan\n",
    "            error = utils.error_helper(obs, goal)\n",
    "            obs_normalized = utils.normalize_obs(obs, goal)\n",
    "            vels_normalized = utils.normalize_obs(vels, goal)\n",
    "            ##### here we store the variables\n",
    "            df = pd.DataFrame({'timepoint': [0], \n",
    "                               'x (cm)': [obs_normalized[0]*unit_scaling], \n",
    "                               'y (cm)': [obs_normalized[1]*unit_scaling], \n",
    "                               'vel_x (cm/s)': [vels_normalized[0]*unit_scaling],\n",
    "                               'vel_y (cm/s)': [vels_normalized[1]*unit_scaling],\n",
    "                               'error (cm)': [error*unit_scaling], \n",
    "                               'angular error (rad)': [angular_error], \n",
    "                               'mode': mode, \n",
    "                               '# LSTM units': lstm_units, \n",
    "                               'experiment': [exp+1], \n",
    "                               'trial': [trial+1], \n",
    "                               'type': kwargs[\"distribution\"], \n",
    "                               'n_batch': [kwargs[\"n_traj\"]], \n",
    "                               'horizon': [kwargs[\"horizon\"]], \n",
    "                               'n_generations': [kwargs[\"generations\"]]})\n",
    "            data_to_store = data_to_store.append(df)\n",
    "\n",
    "            ### do steps in the environment until we reach the maximum step size (e.g. 28 or 2s)\n",
    "            while True:\n",
    "                if render_on:\n",
    "                    is_rendering = True\n",
    "                    env.render()\n",
    "                    time.sleep(0.05)\n",
    "\n",
    "                ### choose action according to our ce planner\n",
    "                next_action, new_plan = ce_planner.agent_step(model=model, \n",
    "                                                   prev_obs=observations[:global_step_counter+1],\n",
    "                                                   prev_vels=velocities[:global_step_counter+1],\n",
    "                                                   prev_actions=actions[:global_step_counter], \n",
    "                                                   prev_resets=reset_bits[:global_step_counter], \n",
    "                                                   goal=goal, \n",
    "                                                   plan_params=None,  \n",
    "                                                   plot=plot_on,\n",
    "                                                   unit_scaling=unit_scaling,\n",
    "                                                   **kwargs)\n",
    "                actions[global_step_counter] = next_action\n",
    "\n",
    "                ### decide if we terminate (either early termination or step limit is reached)\n",
    "                if np.linalg.norm(obs-goal) <= 1.6/unit_scaling:\n",
    "                    at_goal_counter += 1\n",
    "                else:\n",
    "                    at_goal_counter = 0\n",
    "                if at_goal_counter == 7 or local_step_counter == kwargs['n_env_step_max']:\n",
    "                    reset_bits[global_step_counter] = 1\n",
    "                    global_step_counter += 1\n",
    "                    break\n",
    "                else:\n",
    "                    reset_bits[global_step_counter] = 0\n",
    "                    local_step_counter += 1\n",
    "                    global_step_counter += 1\n",
    "\n",
    "                ### we did not terminate early so perform the chosen action in the actual domain\n",
    "                obs, _, _, _ = env.step(next_action)\n",
    "                obs = obs[:2]\n",
    "                vels = env.sim.get_state().qvel[:2]\n",
    "                observations[global_step_counter] = obs\n",
    "                velocities[global_step_counter] = vels\n",
    "\n",
    "                ### determine variables to be measured and stored\n",
    "                angular_error = utils.ang_err_helper(obs, goal)\n",
    "                error = utils.error_helper(obs, goal)\n",
    "                obs_normalized = utils.normalize_obs(obs, goal)\n",
    "                vels_normalized = utils.normalize_obs(vels, goal)\n",
    "                ### here we store the variables\n",
    "                df = pd.DataFrame({'timepoint': [local_step_counter], \n",
    "                                   'x (cm)': [obs_normalized[0]*unit_scaling], \n",
    "                                   'y (cm)': [obs_normalized[1]*unit_scaling], \n",
    "                                   'vel_x (cm/s)': [vels_normalized[0]*unit_scaling],\n",
    "                                   'vel_y (cm/s)': [vels_normalized[1]*unit_scaling],\n",
    "                                   'error (cm)': [error*unit_scaling], \n",
    "                                   'angular error (rad)': [angular_error], \n",
    "                                   'mode': mode, \n",
    "                                   '# LSTM units': lstm_units, \n",
    "                                   'experiment': [exp+1], \n",
    "                                   'trial': [trial+1], \n",
    "                                   'type': kwargs[\"distribution\"], \n",
    "                                   'n_batch': [kwargs[\"n_traj\"]], \n",
    "                                   'horizon': [kwargs[\"horizon\"]], \n",
    "                                   'n_generations': [kwargs[\"generations\"]]})\n",
    "                data_to_store = data_to_store.append(df)\n",
    "                \n",
    "        if is_rendering:\n",
    "            env.close()\n",
    "            is_rendering = False    \n",
    "            \n",
    "        print(('Finished experiment {} ({:.2f} min): | distribution: {} | n: {:d} | ' + \\\n",
    "              'horizon: {:d} | generations: {:d}').format(exp+1, (time.time()-ex_time)/60, kwargs[\"distribution\"], \n",
    "                                                          kwargs[\"n_traj\"], kwargs[\"horizon\"], kwargs[\"generations\"]))\n",
    "        data_to_store.to_pickle(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is for the notebook execution!\n",
    "%matplotlib notebook\n",
    "settings = {'n_experiments': 100,\n",
    "            'n_trials': 7,\n",
    "            'n_env_step_max': 28,\n",
    "            'max_action': 0.2,\n",
    "           \n",
    "            ### planner parameters\n",
    "            'distribution': 'independent',\n",
    "            'elite_fraction': 0.1,\n",
    "            'n_traj': 100,\n",
    "            'horizon': 20,\n",
    "            'generations': 10,\n",
    "            'init_std': 0.3,\n",
    "            'min_std': 0.05}\n",
    "\n",
    "### these are the parameters we want to iterate over\n",
    "lstm_units = [100, 200, 150, 50]\n",
    "modes = ['original', 'rot', 'rotplus']\n",
    "\n",
    "job_list = list(itertools.product(lstm_units, modes))\n",
    "\n",
    "job_id = 6\n",
    "\n",
    "job = job_list[job_id-1]\n",
    "make_model_experiments(suffix=job_id,\n",
    "                         mode = job[1],\n",
    "                         lstm_units = job[0],\n",
    "                         render_on=False,\n",
    "                         plot_on=False,\n",
    "                         save_dir='test',\n",
    "                         models_dir='log',\n",
    "                         **settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### this section is for .py file #####\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('job_id', type=int)\n",
    "    parser.add_argument('save_dir', type=str)\n",
    "    parser.add_argument('--render_on', type=bool, default=False)\n",
    "    args = vars(parser.parse_args())\n",
    "    job_id = args['job_id']\n",
    "    render_on = args['render_on']\n",
    "    save_dir = args['save_dir']\n",
    "\n",
    "    settings = {'n_experiments': 100,\n",
    "                'n_trials': 7,\n",
    "                'n_env_step_max': 28,\n",
    "                'max_action': 0.2,\n",
    "\n",
    "                ### planner parameters\n",
    "                'distribution': 'independent',\n",
    "                'elite_fraction': 0.1,\n",
    "                'n_traj': 100,\n",
    "                'horizon': 20,\n",
    "                'generations': 10,\n",
    "                'init_std': 0.3,\n",
    "                'min_std': 0.05}\n",
    "\n",
    "    ### these are the parameters we want to iterate over\n",
    "    lstm_units = [100, 200, 150, 50]\n",
    "    modes = ['original', 'rot', 'rotplus']\n",
    "\n",
    "    job_list = list(itertools.product(lstm_units, modes))\n",
    "\n",
    "    job = job_list[job_id-1]\n",
    "    make_model_experiments(suffix=job_id,\n",
    "                           mode = job[1],\n",
    "                           lstm_units = job[0],\n",
    "                           render_on=render_on,\n",
    "                           save_dir=save_dir,\n",
    "                           models_dir='log',\n",
    "                           **settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
